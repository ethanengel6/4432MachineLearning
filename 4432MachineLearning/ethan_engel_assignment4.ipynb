import numpy as np
import math
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import RandomizedSearchCV,train_test_split, cross_validate, cross_val_score, GridSearchCV, cross_val_predict, learning_curve
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import Ridge,ElasticNet,LinearRegression, LogisticRegression, SGDClassifier,SGDRegressor, Lasso
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor, BaggingRegressor
from sklearn.metrics import mean_squared_error, confusion_matrix, classification_report, roc_auc_score, roc_curve, r2_score
from sklearn.svm import SVC
from sklearn.pipeline import Pipeline

bike_df = pd.read_csv ('bike_share_hour.csv')
print(bike_df["cnt"].sum())
bike_df = bike_df.astype({"weekday":'category',"season":'category', "holiday":'category', "workingday":'category',"weathersit":'category',"yr":'category',"mnth":'category',"hr":'category'})
print(bike_df.isna().sum().sum())
#Dataframe has no missing values
print(bike_df.describe())

season_df = bike_df.groupby('season')['cnt'].sum().reset_index()
sns.barplot(x = "season",y = 'cnt',data=season_df)
plt.show()
#According to the dataset documentation scheme, spring has the fewest total rides with under 500,000.  Fall has the most with over 1 million.

work_day_df=bike_df.groupby('workingday')['cnt'].sum().reset_index()
sns.barplot(x = "workingday",y = 'cnt',data=work_day_df)
plt.show()
#In terms of totals, workdays have over 2 million rides, while weekend/holidays have about 1 million.

month_df=bike_df.groupby('mnth')['cnt'].sum().reset_index()
sns.barplot(x = "mnth",y = 'cnt',data=month_df)
plt.show()
#There is cleary a seasonal oscillation in the ridership.  The lowest month is January.  From there it increase, peaking from June to September, after which it again decreases into the winter months.

mon_seas_ft = pd.crosstab(index=bike_df["season"], columns=bike_df["mnth"])
print(mon_seas_ft)
#Based upon the 2-way frequency table that this code generates. Season 1 is actually winter, and they progress chronologically from there.  This contradicts the dataset documentation.

weathersit_df=bike_df.groupby('weathersit')['cnt'].sum().reset_index()
sns.barplot(x = "weathersit",y = 'cnt',data=weathersit_df)
plt.show()
#Interestly enough, during extreme weather events(#4 of the variable) is when the fewest bikes are rented.


pointplot_df = bike_df.pivot_table('cnt', ['weathersit', 'season'], aggfunc='sum').reset_index()
sns.pointplot(x = "weathersit",y = "cnt",hue = "season",data = pointplot_df)
plt.show()
#The visual would suggest that the fewest bike rentals are during winter, across all weather situations.  Summer has the highest
#rate of rental during clear, non-stormy weather.  As the weather situations deteriorate, summer & spring rental counts descend
#below autumn slightly.

hour_df=bike_df.groupby('hr')['cnt'].sum().reset_index()
sns.barplot(x = 'hr',y = 'cnt',data=hour_df)
plt.show()
#The peak times for bike rentals are the morning & afternoon commute times.(8am, 6&7pm)

weekend_holiday_df = bike_df.pivot_table('cnt', ['workingday','hr'], aggfunc='sum').reset_index()
weekend_holiday_df2 = weekend_holiday_df.loc[(weekend_holiday_df['workingday']==0)]
sns.barplot(x = 'hr',y = 'cnt',data=weekend_holiday_df2)
plt.show()
#The weekend/holiday bike rental distribution begins incresing early in the morning(6am) & has a single peak in the early afternoon.

#Part 2
cm = bike_df.corr()
print(cm)
#There is not much compelling information from the correlation matrix.  Some of the weather related correlations are intuitive, if not obvious.
#It was interesting that casual riders had a higher r value against the temperature variables than registered riders.

#It seems the quantitative features were already scaled.
bike_df.drop(columns=['casual', 'registered', 'dteday', 'instant'],inplace=True)

sns.histplot(data=bike_df, x="cnt")
plt.show()
#The most common #of riders for any 1 hour time period is fewer than 20.  Larger #s of riders for a 1 hour
#time period are progressively less common.
y_df= bike_df["cnt"]
bike_df.drop(columns=["cnt"], inplace=True)
bike_train, bike_test, y_train, y_test= train_test_split(bike_df,y_df, test_size=0.33, random_state=42)
bike_lin_reg = LinearRegression()
bike_lin_reg.fit(bike_train, y_train)
scores = cross_validate(bike_lin_reg, bike_train, y_train, cv=5, scoring=('r2', 'neg_mean_squared_error'),return_train_score=True)
print("\nTraining r2 score:", np.mean(scores['train_r2']))
training_rmse=(scores['train_neg_mean_squared_error']*-1)**.5
print("\nTraining rmse score:", np.mean(training_rmse))

#Part 3
bike_df2=pd.get_dummies(bike_df, columns=['season','yr','mnth','hr','holiday','weekday','workingday','weathersit'])
bike_train2, bike_test2, y_train2, y_test2= train_test_split(bike_df2,y_df, test_size=0.33, random_state=42)

bike_lin_reg2 = LinearRegression()
bike_lin_reg2.fit(bike_train2, y_train2)
bike2_preds=bike_lin_reg2.predict(bike_train2)
bike2_r2=r2_score(y_train2, bike2_preds)
bike2_mse=mean_squared_error(y_train2, bike2_preds)
print("\n2nd Linear Regression r2 score:", bike2_r2)
bike2_rmse=bike2_mse**.5
print("\n2nd Linear Regression rmse score:", bike2_rmse)

DT_reg = DecisionTreeRegressor(random_state=0)
DT_reg.fit(bike_train2, y_train2)
dt_preds=DT_reg.predict(bike_train2)
dt_r2=r2_score(y_train2, dt_preds)
dt_mse=mean_squared_error(y_train2, dt_preds)
print("\nDecision Tree r2 score:", dt_r2)
dt_rmse=dt_mse**.5
print("\nDecision Tree rmse score:", dt_rmse)

rf_reg =  RandomForestRegressor(random_state=0,n_estimators=30)
rf_reg.fit(bike_train2, y_train2)
rf_preds=rf_reg.predict(bike_train2)
rf_r2=r2_score(y_train2, rf_preds)
rf_mse=mean_squared_error(y_train2, rf_preds)
print("\nRandom Forest r2 score:", rf_r2)
rf_rmse=rf_mse**.5
print("\nRandom Forest rmse score:", rf_rmse)

sgd_reg=SGDRegressor(max_iter=1000,tol=.001)
sgd_reg.fit(bike_train2, y_train2)
sgd_preds=sgd_reg.predict(bike_train2)
sgd_r2=r2_score(y_train2, sgd_preds)
sgd_mse=mean_squared_error(y_train2, sgd_preds)
print("\nSGD r2 score:", sgd_r2)
sgd_rmse=sgd_mse**.5
print("\nSGD rmse score:", sgd_rmse)

lasso_reg=Lasso(alpha=0.1)
lasso_reg.fit(bike_train2, y_train2)
lasso_preds=lasso_reg.predict(bike_train2)
lasso_r2=r2_score(y_train2, lasso_preds)
lasso_mse=mean_squared_error(y_train2, lasso_preds)
print("\nLasso r2 score:", lasso_r2)
lasso_rmse=lasso_mse**.5
print("\nLasso rmse score:", lasso_rmse)

elastic_reg=ElasticNet(random_state=0)
elastic_reg.fit(bike_train2, y_train2)
elastic_preds=elastic_reg.predict(bike_train2)
elastic_r2=r2_score(y_train2, elastic_preds)
elastic_mse=mean_squared_error(y_train2, elastic_preds)
print("\nElastic Net r2 score:", elastic_r2)
elastic_rmse=elastic_mse**.5
print("\nElastic Net rmse score:", elastic_rmse)

ridge_reg = Ridge(alpha=0.5)
ridge_reg.fit(bike_train2, y_train2)
ridge_preds=ridge_reg.predict(bike_train2)
ridge_r2=r2_score(y_train2, ridge_preds)
ridge_mse=mean_squared_error(y_train2, ridge_preds)
print("\nRidge r2 score:", ridge_r2)
ridge_rmse=ridge_mse**.5
print("\nRidge rmse score:", ridge_rmse)

bag_reg = BaggingRegressor()
bag_reg.fit(bike_train2, y_train2)
bag_preds=bag_reg.predict(bike_train2)
bag_r2=r2_score(y_train2, bag_preds)
bag_mse=mean_squared_error(y_train2, bag_preds)
print("\nBagging r2 score:", bag_r2)
bag_rmse=bag_mse**.5
print("\nBagging rmse score:", bag_rmse)

#Part 4
scores = cross_validate(DT_reg, bike_train, y_train, cv=5, scoring=('r2', 'neg_mean_squared_error'),return_train_score=True)
print("\nCross Validated Decision Tree r2 score:", np.mean(scores['train_r2']))
dt_mse2=(scores['train_neg_mean_squared_error']*-1)**.5
print("\nCross Validated Decision Tree rmse score:", np.mean(dt_mse2))

scores = cross_validate(rf_reg, bike_train, y_train, cv=5, scoring=('r2', 'neg_mean_squared_error'),return_train_score=True)
print("\nCross Validated Random Forest r2 score:", np.mean(scores['train_r2']))
rf_mse2=(scores['train_neg_mean_squared_error']*-1)**.5
print("\nCross Validated Random Forest rmse score:", np.mean(rf_mse2))

scores = cross_validate(bag_reg, bike_train, y_train, cv=5, scoring=('r2', 'neg_mean_squared_error'),return_train_score=True)
print("\nCross Validated Bagging r2 score:", np.mean(scores['train_r2']))
bag_mse2=(scores['train_neg_mean_squared_error']*-1)**.5
print("\nCross Validated Bagging rmse score:", np.mean(bag_mse2))

n_estimators = [200,400,600,800,1000,1200,1400,1600,1800,2000]
max_features = ['auto', 'sqrt']
max_depth = [10,20, 30, 40, 50,60,70,80,90,100,110]
min_samples_split = [2, 5, 10]
min_samples_leaf = [1, 2, 4]
bootstrap = [True, False]

random_grid = {'n_estimators': n_estimators,
'max_features': max_features,
'max_depth': max_depth,
'min_samples_split': min_samples_split,
'min_samples_leaf': min_samples_leaf,
'bootstrap': bootstrap}

model_tuned = RandomizedSearchCV(estimator = rf_reg,
param_distributions = random_grid, n_iter = 20, cv = 3, verbose=0, random_state=100 , n_jobs = -1)
search = model_tuned.fit(bike_train2, y_train2)
best_model_tuned=search.best_estimator_

best_model_scores=cross_validate(best_model_tuned, bike_train2, y_train2, cv=5,scoring=('r2', 'neg_mean_squared_error'),return_train_score=True)
print("\nCross Validated Best Estimator r2 score:", np.mean(scores['train_r2']))
print("\nCross Validated Best Estimator mse score:", np.mean(scores['train_neg_mean_squared_error']*-1))
best_rmse=(scores['train_neg_mean_squared_error']*-1)**.5
print("\nCross Validated Best Estimator rmse score:", np.mean(best_rmse))

best_model_test_preds=best_model_tuned.predict(bike_test2)
best_test_r2=r2_score(y_test2, best_model_test_preds)
best_test_mse=mean_squared_error(y_test2, best_model_test_preds)
print("\nFinal Test r2 score:", best_test_r2)
best_test_rmse=best_test_mse**.5
print("\nFinal Test rmse score:", best_test_rmse)
